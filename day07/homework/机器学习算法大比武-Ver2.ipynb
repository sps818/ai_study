{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parker/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/parker/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [12:44:19] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 40078, number of negative: 39922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500975 -> initscore=0.003900\n",
      "[LightGBM] [Info] Start training from score 0.003900\n",
      "算法比较结果：\n",
      "                  Model  Train Time  Predict Time  Accuracy  Precision  Recall  F1 Score\n",
      "0   Logistic Regression        0.18          0.00      0.81       0.82    0.81      0.81\n",
      "1                   SVM       16.91          5.88      0.98       0.98    0.99      0.98\n",
      "2         Decision Tree        2.10          0.00      0.90       0.90    0.90      0.90\n",
      "3         Random Forest       26.20          0.24      0.97       0.97    0.98      0.97\n",
      "4     Gradient Boosting       47.74          0.03      0.91       0.90    0.91      0.91\n",
      "5              AdaBoost        9.42          0.04      0.83       0.83    0.82      0.82\n",
      "6                   KNN        0.00          1.14      0.98       0.98    0.99      0.98\n",
      "7               Bagging       14.03          0.03      0.95       0.96    0.94      0.95\n",
      "8           Extra Trees        4.94          0.35      0.98       0.97    0.98      0.98\n",
      "9                Voting       28.42          0.37      0.95       0.94    0.95      0.95\n",
      "10              XGBoost        0.40          0.01      0.98       0.97    0.98      0.98\n",
      "11             LightGBM        0.62          0.03      0.97       0.96    0.97      0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#下面两个 boosting 的方法 是目前市面上最常用的，但是不再sklearn 的包里，需要单独用命令行 输入 pip install xgboost lightgbm 进行安装。\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 生成假数据\n",
    "X, y = make_classification(n_samples=100000, n_features=20, n_informative=15, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义要比较的算法\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "    \"Voting\": VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression()), \n",
    "        ('rf', RandomForestClassifier()), \n",
    "        ('gnb', DecisionTreeClassifier())\n",
    "    ], voting='hard'),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": lgb.LGBMClassifier()\n",
    "}\n",
    "\n",
    "# 存储结果\n",
    "results = []\n",
    "\n",
    "# 训练和评估每个模型\n",
    "for name, model in models.items():\n",
    "    # 记录训练时间\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    # 记录预测时间\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time.time() - start_time\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # 保存结果\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Time\": train_time,\n",
    "        \"Predict Time\": predict_time,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "# 转换为 DataFrame 并显示\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 设置 pandas 显示选项\n",
    "pd.set_option('display.max_columns', None)  # 显示所有列\n",
    "pd.set_option('display.width', 1000)        # 设置显示宽度\n",
    "pd.set_option('display.float_format', '{:.2f}'.format) # 设置小数点精度\n",
    "print(\"算法比较结果：\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
