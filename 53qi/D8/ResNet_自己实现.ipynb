{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba87797-2fe3-4f28-8167-6a1f41634e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d706caa2-afef-45c6-b9bd-63c83200c7af",
   "metadata": {},
   "source": [
    "# 1. 残差快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba0e899-0965-4f4f-8913-b047d8feb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \"\"\"\n",
    "        残差快：组成残差网络的最小单位\n",
    "        in_channels: 输入通道数\n",
    "        out_channels: 输出通道数\n",
    "        stride: 步长\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "            初始化函数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        # 处理维度不匹配的情况\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride),\n",
    "                                          nn.BatchNorm2d(num_features=out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            前向传播\n",
    "            返回f(x) + 短接\n",
    "        \"\"\"\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        return self.relu(out + self.shortcut(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b487446-6e81-4cce-8d4b-1f610b8a6481",
   "metadata": {},
   "source": [
    "# 2. 残差模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece335ba-4965-4ef8-a9b4-aa30b987e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "        残差模块：由多个残差块（Residual）堆叠而成\n",
    "        num_channels: 每个残差块的输出通道数\n",
    "        num_res: 残差块的数量\n",
    "        first_block: 是否为网络的第一个残差模块\n",
    "    \"\"\"\n",
    "    # def __init__(self, num_channels, num_res, first_block=False):\n",
    "    #     super().__init__()\n",
    "    #     layers = []\n",
    "\n",
    "    #     for i in range(num_res):\n",
    "    #         if i == 0 and not first_block:\n",
    "    #             # 第一个残差快，但不是第一个残差模块时， 下采样+通道变化\n",
    "    #             layers.append(Residual(in_channels=num_channels // 2, out_channels=num_channels, stride=2))\n",
    "    #         else:\n",
    "    #             layers.append(Residual(in_channels=num_channels, out_channels=num_channels))\n",
    "    #     self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_res, first_block=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_res):\n",
    "            if i == 0:\n",
    "                # 第一个残差块，输入输出通道可能不同\n",
    "                stride = 1 if first_block else 2\n",
    "                layers.append(Residual(in_channels, out_channels, stride=stride))\n",
    "            else:\n",
    "                # 后续残差块，输入输出通道一致\n",
    "                layers.append(Residual(out_channels, out_channels, stride=1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bdf57-5158-4e57-8e79-81b483be2e81",
   "metadata": {},
   "source": [
    "# 3. 残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c7f82e-a1da-4eb7-95e3-bf6a7049536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "        残差模块：由输入层， 残差模块层(由多个残差模块组成)， 输出层组成。\n",
    "        num_blocks: 残差模块内的残差快数量\n",
    "        num_classes: 最终分类的数量\n",
    "    \"\"\"\n",
    "    def __init__(self, num_blocks=[3, 4, 6, 3], num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # 输入层，输入的MNIST是黑白图，只有一个通道所以in_channels用的是1\n",
    "        self.input_layer = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "                                         nn.BatchNorm2d(num_features=64),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "        # 残差模块\n",
    "        self.resblock_layer =  nn.Sequential(ResnetBlock(in_channels=64, out_channels=64, num_res=num_blocks[0], first_block=True),\n",
    "                                              ResnetBlock(in_channels=64, out_channels=128, num_res=num_blocks[1]),\n",
    "                                              ResnetBlock(in_channels=128, out_channels=256, num_res=num_blocks[2]),\n",
    "                                              ResnetBlock(in_channels=256, out_channels=512, num_res=num_blocks[3]))\n",
    "\n",
    "        # 全局平均池化和全连接层\n",
    "        self.output_layer =  nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                           nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                                           nn.Linear(in_features=512, out_features=num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.resblock_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeffe49-8243-4307-92d5-1ddff7ae8cf7",
   "metadata": {},
   "source": [
    "# 4. 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6183b88f-8da5-4653-acfe-c8c925ffc5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    自定义模型参数初始化函数\n",
    "    \n",
    "    该函数将被应用在模型的每一个子模块上，\n",
    "    根据模块类型分别进行不同的初始化操作。\n",
    "    \n",
    "    参数:\n",
    "        m (nn.Module): 当前处理的模块（层）\n",
    "    \"\"\"\n",
    "    # 如果当前模块是二维卷积层 (Conv2d)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # 使用 Kaiming 正态分布初始化权重，适用于 ReLU 激活函数\n",
    "        # mode='fan_out' 表示根据输出通道数进行缩放\n",
    "        # nonlinearity='relu' 告知初始化方法使用的是 ReLU 激活函数\n",
    "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "        # 如果卷积层包含偏置项，则将其初始化为 0\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)  # 将偏置初始化为常数 0\n",
    "\n",
    "    # 如果当前模块是二维批归一化层 (BatchNorm2d)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        # 批归一化层的 weight 表示 gamma 缩放因子，默认初始化为 1\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        \n",
    "        # 批归一化层的 bias 表示 beta 平移因子，默认初始化为 0\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96365ad0-149b-43e9-9a02-4135df25d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 数据预处理，也可以叫数据增强/图像增强\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 将图片缩放到224x224，适配ResNet输入\n",
    "    transforms.ToTensor(),          # 将PIL图片或numpy数组转换为张量，并归一化到[0,1]\n",
    "])\n",
    "\n",
    "# 下载MNIST训练集，并应用预处理\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',         # 数据存放目录\n",
    "    train=True,            # 是否为训练集\n",
    "    download=True,         # 如无则自动下载\n",
    "    transform=transform    # 应用上面定义的预处理\n",
    ")\n",
    "# 下载MNIST测试集，并应用预处理\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,           # 是否为测试集\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 划分部分训练集用于验证\n",
    "train_size = int(0.9 * len(train_dataset))  # 90%作为训练集\n",
    "val_size = len(train_dataset) - train_size  # 剩余10%作为验证集\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])  # 随机划分\n",
    "\n",
    "# 构建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)   # 训练集加载器，打乱顺序\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)      # 验证集加载器，不打乱\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)    # 测试集加载器，不打乱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a4aef-f8da-4819-98bb-0cd42bbb844b",
   "metadata": {},
   "source": [
    "# 5. 模型训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8426fa46-6fd9-41a0-b93c-ce25801a6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 实例化ResNet模型，指定每个残差模块的残差块数量和分类数，并将模型移动到指定设备\n",
    "mynet = ResNet(num_blocks=[2, 2, 2, 2], num_classes=10).to(device)\n",
    "mynet.apply(init_weights)    # 应用初始化\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()  # 定义损失函数为交叉熵损失，常用于多分类任务\n",
    "# optimizer = optim.SGD(mynet.parameters(), lr=0.01, momentum=0.9)  # 定义优化器为SGD，学习率0.01，动量为0.9\n",
    "optimizer = optim.AdamW(mynet.parameters(), lr=3e-4, weight_decay=1e-4)  # 目前公认的最好用的优化器\n",
    "\n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    \"\"\"\n",
    "    训练函数\n",
    "    model: 要训练的模型\n",
    "    loader: 数据加载器\n",
    "    optimizer: 优化器\n",
    "    loss_fn: 损失函数\n",
    "    device: 计算设备\n",
    "    返回：平均损失和准确率\n",
    "    \"\"\"\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    total_loss, total_correct = 0, 0  # 初始化损失和正确数\n",
    "    for data, target in loader:  # 遍历所有批次\n",
    "        data, target = data.to(device), target.to(device)  # 将数据和标签移动到设备\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        output = model(data)  # 前向传播，得到模型输出\n",
    "        loss = loss_fn(output, target)  # 计算损失\n",
    "        loss.backward()  # 反向传播，计算梯度\n",
    "        optimizer.step()  # 更新参数\n",
    "        total_loss += loss.item() * data.size(0)  # 累加损失（乘以批次大小）\n",
    "        total_correct += (output.argmax(1) == target).sum().item()  # 累加预测正确的样本数\n",
    "    avg_loss = total_loss / len(loader.dataset)  # 计算平均损失\n",
    "    avg_acc = total_correct / len(loader.dataset)  # 计算平均准确率\n",
    "    return avg_loss, avg_acc  # 返回平均损失和准确率\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    \"\"\"\n",
    "    验证/测试函数\n",
    "    model: 要评估的模型\n",
    "    loader: 数据加载器\n",
    "    loss_fn: 损失函数\n",
    "    device: 计算设备\n",
    "    返回：平均损失和准确率\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss, total_correct = 0, 0  # 初始化损失和正确数\n",
    "    with torch.no_grad():  # 关闭梯度计算，节省内存和加速\n",
    "        for data, target in loader:  # 遍历所有批次\n",
    "            data, target = data.to(device), target.to(device)  # 将数据和标签移动到设备\n",
    "            output = model(data)  # 前向传播\n",
    "            loss = loss_fn(output, target)  # 计算损失\n",
    "            total_loss += loss.item() * data.size(0)  # 累加损失\n",
    "            total_correct += (output.argmax(1) == target).sum().item()  # 累加预测正确的样本数\n",
    "    avg_loss = total_loss / len(loader.dataset)  # 计算平均损失\n",
    "    avg_acc = total_correct / len(loader.dataset)  # 计算平均准确率\n",
    "    return avg_loss, avg_acc  # 返回平均损失和准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03adfb4-1631-4953-a3ea-c81738fd1e7e",
   "metadata": {},
   "source": [
    "# 6. 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60762eac-4983-4544-9f1d-f5094553024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1290, Train Acc=0.9637, Val Loss=0.0709, Val Acc=0.9800\n",
      "Epoch 2: Train Loss=0.0349, Train Acc=0.9891, Val Loss=0.0442, Val Acc=0.9870\n",
      "Epoch 3: Train Loss=0.0246, Train Acc=0.9926, Val Loss=0.0514, Val Acc=0.9832\n",
      "Epoch 4: Train Loss=0.0213, Train Acc=0.9933, Val Loss=0.0530, Val Acc=0.9833\n",
      "Epoch 5: Train Loss=0.0163, Train Acc=0.9952, Val Loss=0.0261, Val Acc=0.9918\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # 训练3个轮次（epoch）\n",
    "    train_loss, train_acc = train(mynet, train_loader, optimizer, loss_fn, device)  # 在训练集上训练，并返回损失和准确率\n",
    "    val_loss, val_acc = evaluate(mynet, val_loader, loss_fn, device)  # 在验证集上评估模型，并返回损失和准确率\n",
    "    # 打印当前轮次的训练损失、训练准确率、验证损失和验证准确率\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72015a6f-e67a-4914-b05d-0c8c811d2dd5",
   "metadata": {},
   "source": [
    "# 7. 测试集评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ff9938-b2c6-4c59-840d-5d8ccd96f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=0.0288, Test Acc=0.9894\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(mynet, test_loader, loss_fn, device)  # 在测试集上评估模型，返回损失和准确率\n",
    "print(f\"Test Loss={test_loss:.4f}, Test Acc={test_acc:.4f}\")  # 打印测试集的损失和准确率"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(py311)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
