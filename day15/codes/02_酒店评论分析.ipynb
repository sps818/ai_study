{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b09f20-94dd-4ac6-b4af-4c25d994f2f8",
   "metadata": {},
   "source": [
    "### 1. 样本路径和类别读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad106c89-1433-4458-b62d-a9f75e85dcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    训练数据聚合\n",
    "\"\"\"\n",
    "import os\n",
    "train_root = os.path.join(\"hotel\", \"train\")\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for label in os.listdir(train_root):\n",
    "    label_root = os.path.join(train_root, label)\n",
    "    for file in os.listdir(label_root):\n",
    "        file_path = os.path.join(label_root, file)\n",
    "        # 聚合结果\n",
    "        train_texts.append(file_path)\n",
    "        train_labels.append(label)\n",
    "# 打印数据\n",
    "len(train_texts), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fb5d73f-55b7-44b5-97a0-51440c5e579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    测试数据聚合\n",
    "\"\"\"\n",
    "test_root = os.path.join(\"hotel\", \"test\")\n",
    "test_texts = []\n",
    "test_labels = []\n",
    "for label in os.listdir(test_root):\n",
    "    label_root = os.path.join(test_root, label)\n",
    "    for file in os.listdir(label_root):\n",
    "        file_path = os.path.join(label_root, file)\n",
    "        # 聚合结果\n",
    "        test_texts.append(file_path)\n",
    "        test_labels.append(label)\n",
    "# 打印数据\n",
    "len(test_texts), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25896509-1a1f-4f43-abec-3521dc2b588b",
   "metadata": {},
   "source": [
    "### 2. 构建分词器\n",
    "- 分词，把句子变 token\n",
    "- 把所有不同的token聚在一起\n",
    "- 做 0 ~ N-1 的编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e82aee1-5f49-409d-9496-0e70c01ae793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "# pip install opencc -U\n",
    "import opencc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7501106a-9db2-47ec-9167-da5d2f8120d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    \"\"\"\n",
    "        定义一个分词器\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "            训练的语料\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.t2s = opencc.OpenCC(config=\"t2s\")\n",
    "        self._build_dict()\n",
    "\n",
    "    def _build_dict(self):\n",
    "        \"\"\"\n",
    "            构建字典\n",
    "        \"\"\"\n",
    "        # 1. 获取所有的 token\n",
    "        words = {\"<PAD>\", \"<UNK>\"}\n",
    "        for file in self.X:\n",
    "            # 1. 打开文件\n",
    "            with open(file=file, mode=\"r\", encoding=\"gbk\", errors=\"ignore\") as f:\n",
    "                text = f.read().replace(\"\\n\", \"\")\n",
    "                text = self.t2s.convert(text=text)\n",
    "                words.update(set(jieba.lcut(text)))\n",
    "        # 2. 构建文本字典\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(words)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        # 3. 删掉 数据集\n",
    "        del self.X\n",
    "        # 4. 构建标签字典\n",
    "        labels = set(train_labels)\n",
    "        self.label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "        self.idx2label = {idx: label for label, idx in self.label2idx.items()}\n",
    "        # 5. 删除 数据集\n",
    "        del self.y\n",
    "        \n",
    "\n",
    "    def encode(self, text, seq_len):\n",
    "        \"\"\"\n",
    "            text --> tokens --> ids\n",
    "        \"\"\"\n",
    "        # 1. 繁体转简体\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        text = self.t2s.convert(text=text)\n",
    "        # 2. 分词\n",
    "        text = jieba.lcut(text)\n",
    "        # 3. 统一长度\n",
    "        text = (text + [\"<PAD>\"] * seq_len)[:seq_len]\n",
    "        # 4. 转 id\n",
    "        ids = [self.word2idx.get(word, self.word2idx.get(\"<UNK>\")) for word in text]\n",
    "        \n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        \"\"\"\n",
    "            ids --> tokens --> text\n",
    "        \"\"\"\n",
    "        text = \"\".join([self.idx2word.get(_id, \"\") for _id in ids])\n",
    "        return text\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "            输: 分词器基本信息\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "        Tokenizer Info: \n",
    "            --> Num of Tokens: {len(self.word2idx)}\n",
    "            --> Num of Labels: {len(self.label2idx)}\n",
    "        \"\"\"\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d7590-05cb-4976-abc5-271efbfabd5d",
   "metadata": {},
   "source": [
    "### 3. 打包数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c683fa-a60a-44c0-9169-aa9ea4e6bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32834726-75af-46cc-bfe3-733348f19ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelCommentDataset(Dataset):\n",
    "    \"\"\"\n",
    "        自定义数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, seq_len=65):\n",
    "        \"\"\"\n",
    "            初始化\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            索引操作\n",
    "                返回第idx个样本\n",
    "        \"\"\"\n",
    "        # 1. 文本\n",
    "        file = self.X[idx]\n",
    "        with open(file=file, mode=\"r\", encoding=\"gbk\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "            ids = tokenizer.encode(text=text, seq_len=self.seq_len)\n",
    "            ids = torch.tensor(data=ids, dtype=torch.long)\n",
    "                \n",
    "        # 2. 标签\n",
    "        label = self.y[idx]\n",
    "        label = tokenizer.label2idx.get(label)\n",
    "        label = torch.tensor(data=label, dtype=torch.long)\n",
    "        \n",
    "        return ids, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff9e0525-bfa9-411f-9791-261eab463dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        Tokenizer Info: \n",
       "            --> Num of Tokens: 20781\n",
       "            --> Num of Labels: 2\n",
       "        "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 定义一个分词器\n",
    "tokenizer = Tokenizer(X=train_texts, y=train_labels)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27aa23f9-9ab2-4911-bf22-536619a860a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 打包数据\n",
    "train_dataset = HotelCommentDataset(X=train_texts, y=train_labels)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=128)\n",
    "test_dataset = HotelCommentDataset(X=test_texts, y=test_labels)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbb2a22-f816-4a78-ba56-3f25d3fbb609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 65])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405343ba-dc1c-47ac-a35f-1bfbb2216fea",
   "metadata": {},
   "source": [
    "### 4. 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c9060-2b82-4ed3-b0fc-1b20da091c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
