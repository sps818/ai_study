{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da68ee12-93a0-414b-a0ac-f07f45708958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d41c6de-e0c7-4e47-8d0d-16b3facd78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二维卷积：H 和 W 两个方向做卷积\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, stride=2, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe37204-5a5f-443b-8222-738cc7e739e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟图像 [N, C, H, W]\n",
    "X = torch.randn(1, 3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea12b1a-48a3-482c-a3fc-a5406f50d283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53cf3be9-a79c-4185-80f8-bf73c359c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d453e47d-cf43-4554-b32b-914aed676233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83970d30-1adc-4ad8-b78b-bb2c522e77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批规范化层\n",
    "bn = nn.BatchNorm2d(num_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3fd4c8c-4cb7-4f92-b907-9e1e13b7e682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8313d8d-c4ae-4b75-a4d6-69e7c24a802b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815862e3-3fb0-48e1-abf1-706c1e7fab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.relu>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "310c7c6e-6b57-4d97-9f2e-bc30adf5a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大池化、亚采样、把图像变小，丢掉不重要的特征，保留最重要的特征\n",
    "mp = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2cc95b6-db62-4595-8366-cce23242d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randint(low=0, high=101, size=(1, 1, 4, 4),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55432375-7063-4f28-8f98-0bcaed607afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [N, C, H, W]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7a9e7d2-29c0-44ea-97ad-62695cae06b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[91.,  2.,  5., 29.],\n",
       "          [ 6., 99., 52.,  9.],\n",
       "          [61., 75., 51., 94.],\n",
       "          [72., 38., 26., 31.]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72696ccc-e2c9-4c4e-9879-5227f6229193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[99., 52.],\n",
       "          [75., 94.]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1b42ef0-17d1-491e-ac3c-903827948d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea093c70-240b-4fc9-8631-eb3fe68d788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[91.,  2.,  5., 29.],\n",
       "          [ 6., 99., 52.,  9.],\n",
       "          [61., 75., 51., 94.],\n",
       "          [72., 38., 26., 31.]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b80a060c-1cde-405e-8ccf-2d51383e15a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[49.5000, 23.7500],\n",
       "          [61.5000, 50.5000]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42ff0374-c237-4727-8eb6-66a70499ca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.5000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, :, :2, :2].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06f754-f452-4dbe-b3d9-6004d0a01f45",
   "metadata": {},
   "source": [
    "### 搭建一个LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15d1a4-7161-4b62-ba9a-67d1250da78c",
   "metadata": {},
   "source": [
    "![LeNet5](lenet5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e565b793-a7bc-4e7c-8b02-3fe7f92eda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b93fa00-9832-4a02-8d2e-7a33727c76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "        自定义一个神经网络\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, n_classes=10):\n",
    "        \"\"\"\n",
    "            初始化\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                               out_channels=6, \n",
    "                               kernel_size=5,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, \n",
    "                                stride=2,\n",
    "                                padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,\n",
    "                              out_channels=16,\n",
    "                              kernel_size=5,\n",
    "                              stride=1,\n",
    "                              padding=0)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, \n",
    "                               stride=2,\n",
    "                               padding=0)\n",
    "        self.flatten = nn.Flatten(start_dim=1,\n",
    "                                  end_dim=-1)\n",
    "        self.fc1 = nn.Linear(in_features=400,\n",
    "                            out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120,\n",
    "                            out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84,\n",
    "                            out_features=n_classes)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            前向传播\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4c7c1a8-11d5-44a1-94e3-697db6ad635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "        自定义一个神经网络\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, n_classes=10):\n",
    "        \"\"\"\n",
    "            初始化\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # 1. 特征抽取\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, \n",
    "                               out_channels=6, \n",
    "                               kernel_size=5,\n",
    "                               stride=1,\n",
    "                               padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                                stride=2,\n",
    "                                padding=0),\n",
    "            nn.Conv2d(in_channels=6,\n",
    "                              out_channels=16,\n",
    "                              kernel_size=5,\n",
    "                              stride=1,\n",
    "                              padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                               stride=2,\n",
    "                               padding=0)\n",
    "        )\n",
    "\n",
    "        # 2. 分类输出\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(in_features=400, out_features=120),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Linear(in_features=84, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            前向传播\n",
    "        \"\"\"\n",
    "        # 1. 先做特征抽取\n",
    "        x = self.feature_extractor(x)\n",
    "        # 2. 再做分类回归\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fdd8a8af-1c95-4f5b-a0c2-5b6f215dc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24137a0d-3786-4223-804a-13eedff45a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(2, 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d915212c-f846-4923-a7c2-44fc75abdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d5f4f94f-f378-4a34-8ece-85acbdf849b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8208d05e-830d-4c05-b5fe-94c47e213d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcdd40-a620-4afa-899d-967c329a03d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
