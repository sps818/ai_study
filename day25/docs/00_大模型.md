### `大`模型？
- 大语言模型 
- Large Language Models (LLMs)
- 参数量：B Billion 十亿
    - 1. 类脑设计：参数看作脑细胞，脑细胞越多，越聪明
    - 2. 数学视角：y=F(x), 参数看作自变量，自变量越多，函数越复杂，越能映射复杂的关系
- 训练平台：
    - 工程上：不可能脱离GPU，而且需要高性能GPU！
    - 万卡平台
- 训练数据：
    - 预训练：18T语料（3600万本红楼梦量级）
- 训练时长：
    - 原来：3~6个月
    - 现在：1~2个月

### `质`的变化
- 本质：话天下大势，分久必合，合久必分
- 1. 小模型时代：
    - 单一职责原则：
        - 一个场景：
            - 单独一个模型
            - 单独一个数据集
            - 单独训练
            - 单独评估
            - 单独部署
            - 单独维护
    - 一个系统：
        - 挂了很多微服务
        - 挂了很多的小模型
- 2. 大模型时代：
    - 大一统
        - 一个系统：
            - 挂了一个大模型
                - 通过指令遵循，可以同时解决不同的问题！！！
            - 多模态大模型

### 生成式人工智能 VS 判别式人工智能
- Generative AI
- 创作性
- 如何进行`人机协同`是下一步的重点！
- 具身机器人
