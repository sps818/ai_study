### 大语言模型的架构：
- 架构1：Encoder-Decoder 架构（完全淘汰了）
    - 直接把 Transformer 变厚即可！
    - T5：Text to Text transfer Transformer
    - Google
    - 最正确、最正统、最没有歧义的路线！！！
    - 首次提出：`指令编码`的基础理念

- 架构2：Decoder-Only 架构（主流架构！！！）
    - 把模型的复杂度降低！
    - 除了GLM之外，这种架构是唯一的！
        - LLaMA 架构
            - LLaMA2
        - 千问系列(*****)
        - 豆包
        - 星火
        - kimi
        - ...

- 架构3：GLM（Prefix-Encoder-Only）架构
    - 融合BERT和GPT的优势，提出了一种混合结构！
    - 1. 理解上文：双向编码器的优势（BERT）
    - 2. 生成下文：强大的自回归能力（GPT）

